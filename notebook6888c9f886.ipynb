{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"First thing first: kaggle api key for downloading dataset","metadata":{}},{"cell_type":"code","source":"import json\nimport os\n\n# Replace 'your_kaggle_username' and 'your_api_key' with your actual values\nkaggle_credentials = {\"username\":\"ghostysh\",\"key\":\"2d9c751653ff10a0d920bed39841c7a1\"}\n\n# Save the credentials to the kaggle.json file\nos.makedirs(\"/root/.kaggle/\", exist_ok=True)\n#/root/.config/kaggle/\nwith open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n    json.dump(kaggle_credentials, f)\n\n# Set permissions for the file\nos.chmod(\"/root/.kaggle/kaggle.json\", 600)\n\nprint(\"kaggle.json created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:35:35.160496Z","iopub.execute_input":"2025-02-03T23:35:35.160818Z","iopub.status.idle":"2025-02-03T23:35:35.166595Z","shell.execute_reply.started":"2025-02-03T23:35:35.160765Z","shell.execute_reply":"2025-02-03T23:35:35.165794Z"}},"outputs":[{"name":"stdout","text":"kaggle.json created successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**Technical assignment 3**\n\n**Santeri Hukari**\n\n\n**Part 1: Dataset Preparation and Fine-Tuning (7 points)**\n\n**Step 1: Download the IMDB Dataset (1 point)**\n1. Use the IMDB dataset from Kaggle: /kaggle/input/imdb-dataset/IMDB\nDataset.csv.\n2. Load the dataset using Pandas and verify it in your notebook.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle.api.kaggle_api_extended import KaggleApi\n\n# Move kaggle.json to the correct location\n#!mkdir -p ~/.kaggle\n!cp /root/.kaggle/kaggle.json /root/.config/kaggle/\n#!cp /kaggle/working/kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n\n# Initialize the Kaggle API\napi = KaggleApi()\napi.authenticate()\n\n# Download the IMDB dataset\ndataset_name = \"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\"\ndownload_path = \"/kaggle/working\"\n\n# Download and unzip the dataset\napi.dataset_download_files(dataset_name, path=download_path, unzip=True)\n\n# Verify the download\nprint(\"Downloaded files:\", os.listdir(download_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:35:47.438807Z","iopub.execute_input":"2025-02-03T23:35:47.439113Z","iopub.status.idle":"2025-02-03T23:35:48.861962Z","shell.execute_reply.started":"2025-02-03T23:35:47.439088Z","shell.execute_reply":"2025-02-03T23:35:48.861022Z"}},"outputs":[{"name":"stdout","text":"Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\nDownloaded files: ['IMDB Dataset.csv', '.virtual_documents']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!ls /root/.config/kaggle/\n!ls /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:36:26.573861Z","iopub.execute_input":"2025-02-03T23:36:26.574219Z","iopub.status.idle":"2025-02-03T23:36:26.822265Z","shell.execute_reply.started":"2025-02-03T23:36:26.574192Z","shell.execute_reply":"2025-02-03T23:36:26.821104Z"}},"outputs":[{"name":"stdout","text":"kaggle.json\n'IMDB Dataset.csv'\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\n\n# Path to the dataset\ndataset_path = \"/kaggle/working/IMDB Dataset.csv\"\n\n# Load the dataset\ndf = pd.read_csv(dataset_path)\n\n# Display the first few rows\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:36:32.696258Z","iopub.execute_input":"2025-02-03T23:36:32.696573Z","iopub.status.idle":"2025-02-03T23:36:33.365913Z","shell.execute_reply.started":"2025-02-03T23:36:32.696546Z","shell.execute_reply":"2025-02-03T23:36:33.365028Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"**Step 2: Data Preprocessing (1 point)**\n1. Clean and preprocess the dataset:\n  - Encode the sentiment column (positive -> 1, negative -> 0).\n  - Retain only the review and label columns.\n2. Split the data into training and validation, testing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Dataset path\ndataset_path = \"/kaggle/working/IMDB Dataset.csv\"\n\n# Load the dataset\ndf = pd.read_csv(dataset_path)\n\n# Encode the sentiment column: positive -> 1, negative -> 0\ndf['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n\n# Retain only the review and label columns\ndf = df[['review', 'sentiment']]\n\n# Split the data into training, validation, and testing sets\ntrain_data, temp_data = train_test_split(df, test_size=0.3, random_state=42, stratify=df['sentiment'])\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['sentiment'])\n\n# Print dataset sizes for verification\nprint(\"Training set size:\", len(train_data))\nprint(\"Validation set size:\", len(val_data))\nprint(\"Testing set size:\", len(test_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:36:39.011067Z","iopub.execute_input":"2025-02-03T23:36:39.011372Z","iopub.status.idle":"2025-02-03T23:36:39.717216Z","shell.execute_reply.started":"2025-02-03T23:36:39.011347Z","shell.execute_reply":"2025-02-03T23:36:39.716230Z"}},"outputs":[{"name":"stdout","text":"Training set size: 35000\nValidation set size: 7500\nTesting set size: 7500\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**Step 3: Model Selection and Tokenization (1 point)**\n\n**1. Select a pre-trained Hugging Face transformer model for fine-tuning (e.g., distilbert-base-uncased).**\n\n**2. Tokenize the dataset with (see if required)**\n- Truncation.\n- Padding.\n- Maximum sequence length of 256.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Select the pre-trained model (e.g., DistilBERT)\nmodel_name = \"distilbert-base-uncased\"\n\n# Load the tokenizer for the selected model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Tokenize the dataset with truncation, padding, and max length\ndef tokenize_data(data):\n    return tokenizer(\n        data['review'].tolist(),\n        truncation=True,\n        padding=True,  # Add padding\n        max_length=256,  # Set max sequence length\n        return_tensors='pt'  # Return PyTorch tensors\n    )\n\n# Tokenize training, validation, and testing datasets\ntrain_encodings = tokenize_data(train_data)\nval_encodings = tokenize_data(val_data)\ntest_encodings = tokenize_data(test_data)\n\n# Print a sample of tokenized data for verification\nprint(\"Tokenized Training Data:\", train_encodings.input_ids.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:37:58.529911Z","iopub.execute_input":"2025-02-03T23:37:58.530218Z","iopub.status.idle":"2025-02-03T23:38:31.242424Z","shell.execute_reply.started":"2025-02-03T23:37:58.530196Z","shell.execute_reply":"2025-02-03T23:38:31.241468Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fadb761d356437d9d02d647a7a40bf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24fd51abc7264a10a8345e4fd0887762"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b025bfcf713443c5ad242da1af223d10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cca41a0c8ee942acbbd68d78c576f7a1"}},"metadata":{}},{"name":"stdout","text":"Tokenized Training Data: torch.Size([35000, 256])\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Step 4: Fine-Tune the Model (2 points)**\n1. Fine-tune the model on the IMDB dataset for 2 epochs using the Hugging Face\nTrainer.\n2. Set training parameters:\n- Learning rate: 5e-5 or your own\n- Batch size: 16 or 32\n- Evaluation at the end of each epoch.\n\n3. Ensure that metrics like accuracy, precision, recall, and F1-score are logged\nduring training.","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:45:42.275324Z","iopub.execute_input":"2025-02-03T23:45:42.275696Z","iopub.status.idle":"2025-02-03T23:45:47.159333Z","shell.execute_reply.started":"2025-02-03T23:45:42.275653Z","shell.execute_reply":"2025-02-03T23:45:47.158322Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import Dataset\nimport evaluate\nimport numpy as np\n\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Convert the dataframes to Hugging Face Dataset objects\ndef prepare_dataset(data, encodings):\n    dataset = Dataset.from_dict({\n        'input_ids': encodings['input_ids'],\n        'attention_mask': encodings['attention_mask'],\n        'labels': data['sentiment'].tolist()\n    })\n    return dataset\n\ntrain_dataset = prepare_dataset(train_data, train_encodings)\nval_dataset = prepare_dataset(val_data, val_encodings)\ntest_dataset = prepare_dataset(test_data, test_encodings)\n\n# Load pre-trained model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\n# Define metrics\nmetric = evaluate.load(\"accuracy\")\nprecision_metric = evaluate.load(\"precision\")\nrecall_metric = evaluate.load(\"recall\")\nf1_metric = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    accuracy = metric.compute(predictions=predictions, references=labels)\n    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"binary\")\n    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"binary\")\n    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"binary\")\n    return {\n        \"accuracy\": accuracy[\"accuracy\"],\n        \"precision\": precision[\"precision\"],\n        \"recall\": recall[\"recall\"],\n        \"f1\": f1[\"f1\"],\n    }\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",          # Output directory\n    evaluation_strategy=\"epoch\",    # Evaluate at the end of each epoch\n    learning_rate=5e-5,             # Learning rate\n    per_device_train_batch_size=16, # Batch size per device\n    per_device_eval_batch_size=16,  # Evaluation batch size\n    num_train_epochs=2,             # Number of epochs\n    weight_decay=0.01,              # Weight decay for regularization\n    logging_dir=\"./logs\",           # Logging directory\n    logging_steps=50,               # Log every 50 steps\n    save_strategy=\"epoch\",          # Save model at the end of each epoch\n    save_total_limit=1,             # Keep only the latest checkpoint\n    load_best_model_at_end=True,    # Load the best model at the end of training\n    metric_for_best_model=\"accuracy\" # Metric for selecting the best model\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\n# Fine-tune the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T23:47:14.053000Z","iopub.execute_input":"2025-02-03T23:47:14.053307Z","iopub.status.idle":"2025-02-04T00:03:03.819159Z","shell.execute_reply.started":"2025-02-03T23:47:14.053281Z","shell.execute_reply":"2025-02-04T00:03:03.818267Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n<ipython-input-20-25560fd943dc>:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4376' max='4376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4376/4376 15:44, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.250900</td>\n      <td>0.276810</td>\n      <td>0.905200</td>\n      <td>0.876954</td>\n      <td>0.942667</td>\n      <td>0.908624</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.109700</td>\n      <td>0.308114</td>\n      <td>0.915067</td>\n      <td>0.911011</td>\n      <td>0.920000</td>\n      <td>0.915484</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4376, training_loss=0.21126504272385968, metrics={'train_runtime': 945.8835, 'train_samples_per_second': 74.005, 'train_steps_per_second': 4.626, 'total_flos': 4636358952960000.0, 'train_loss': 0.21126504272385968, 'epoch': 2.0})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Get the training metrics\ntraining_metrics = trainer.state.log_history\n\n# Filter the metrics to include only evaluation logs\neval_metrics = [entry for entry in training_metrics if \"eval_loss\" in entry]\n\n# Convert to a Pandas DataFrame for better visualization\nmetrics_df = pd.DataFrame(eval_metrics)\n\n# Select only relevant columns for display\ncolumns_to_display = [\"epoch\", \"eval_loss\", \"eval_accuracy\", \"eval_precision\", \"eval_recall\", \"eval_f1\"]\nmetrics_df = metrics_df[columns_to_display]\n\n# Display the table\nprint(metrics_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:06:19.249712Z","iopub.execute_input":"2025-02-04T00:06:19.250179Z","iopub.status.idle":"2025-02-04T00:06:19.263692Z","shell.execute_reply.started":"2025-02-04T00:06:19.250144Z","shell.execute_reply":"2025-02-04T00:06:19.262413Z"}},"outputs":[{"name":"stdout","text":" epoch  eval_loss  eval_accuracy  eval_precision  eval_recall  eval_f1\n   1.0   0.276810       0.905200        0.876954     0.942667 0.908624\n   2.0   0.308114       0.915067        0.911011     0.920000 0.915484\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"**Step 5: Save and Upload the Model to Hugging Face (2 points)**\n1. Save the fine-tuned model and tokenizer locally using save_pretrained().\n2. Log in to Hugging Face using notebook_login.\n3. Upload the model to Hugging Face using push_to_hub.\n4. Verify the model on Hugging Face Hub and include the link in your notebook.","metadata":{}},{"cell_type":"code","source":"# Save the fine-tuned model and tokenizer locally\nmodel_save_path = \"./fine_tuned_model\"\nmodel.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\n\nprint(f\"Model saved at: {model_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:07:00.984936Z","iopub.execute_input":"2025-02-04T00:07:00.985313Z","iopub.status.idle":"2025-02-04T00:07:01.702441Z","shell.execute_reply.started":"2025-02-04T00:07:00.985287Z","shell.execute_reply":"2025-02-04T00:07:01.701569Z"}},"outputs":[{"name":"stdout","text":"Model saved at: ./fine_tuned_model\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\n# Log in to Hugging Face\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:12:12.234866Z","iopub.execute_input":"2025-02-04T00:12:12.235194Z","iopub.status.idle":"2025-02-04T00:12:12.254564Z","shell.execute_reply.started":"2025-02-04T00:12:12.235171Z","shell.execute_reply":"2025-02-04T00:12:12.253498Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"946843f7d6034c008f4096afffa59c87"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"!pip install huggingface_hub\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:12:58.682249Z","iopub.execute_input":"2025-02-04T00:12:58.682796Z","iopub.status.idle":"2025-02-04T00:13:02.396174Z","shell.execute_reply.started":"2025-02-04T00:12:58.682733Z","shell.execute_reply":"2025-02-04T00:13:02.395197Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.12.14)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Push the model to the Hugging Face Hub\nmodel_name_on_hub = \"fine-tuned-imdb-model\"\nrepo_url = model.push_to_hub(model_name_on_hub)\n\n# Push the tokenizer to the same repo\ntokenizer.push_to_hub(model_name_on_hub)\n\nprint(f\"Model uploaded to Hugging Face Hub: {repo_url}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T00:14:56.459897Z","iopub.execute_input":"2025-02-04T00:14:56.460269Z","iopub.status.idle":"2025-02-04T00:15:08.787411Z","shell.execute_reply.started":"2025-02-04T00:14:56.460245Z","shell.execute_reply":"2025-02-04T00:15:08.786498Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1cce5874d284b6aad968ed98aac9505"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e247e10de9f45c79542fd5848d27680"}},"metadata":{}},{"name":"stdout","text":"Model uploaded to Hugging Face Hub: https://huggingface.co/santerihukari/fine-tuned-imdb-model/commit/77e691894d2e9e742aab7772f2c755ab22aa33df\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"In case the output vanishes:\n\n\"Model uploaded to Hugging Face Hub: https://huggingface.co/santerihukari/fine-tuned-imdb-model/commit/77e691894d2e9e742aab7772f2c755ab22aa33df\"","metadata":{}},{"cell_type":"markdown","source":"**Part 2: API Development and Testing (5 points)**\n\n\n**Note:** from now on everything is done locally. All files are included in the github repository.","metadata":{}},{"cell_type":"markdown","source":"**Step 6: Set Up the Backend API (1 point)**\n1. Use FastAPI or Flask, Express, Nest Nodejs to create an API.\n2. Define a POST endpoint (/analyze/) that:\n\n- Accepts:\n  - text: The input text for sentiment analysis.\n  - model: A parameter specifying the model to use (custom or llama).\n\n- Returns:\n  - Sentiment (positive or negative).\n  - Confidence score.","metadata":{}},{"cell_type":"markdown","source":"```bash\n(LLM3) santeri@LAPTOP-67I7VNKD:~$ curl -X 'POST' \\\n  'http://127.0.0.1:8000/analyze/' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"text\": \"I love this movie!\", \"model\": \"custom\"}'\n{\"sentiment\":\"positive\",\"confidence\":0.92798}\n\n(LLM3) santeri@LAPTOP-67I7VNKD:~$ curl -X 'POST' \\\n  'http://127.0.0.1:8000/analyze/' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"text\": \"I hate this movie!\", \"model\": \"custom\"}'\n{\"sentiment\":\"negative\",\"confidence\":0.9756002426147461}\n```","metadata":{}},{"cell_type":"markdown","source":"**Step 7: Load Models (1 point)**\n1. Load the fine-tuned model from Hugging Face.\n2. Access the Llama 3 model using the Groq Cloud API\n","metadata":{}},{"cell_type":"markdown","source":"**Step 8: Test the API Locally (1 point)**\n1. Test the /analyze/ endpoint with both models (custom and llama) using:\n- Postman.\n- curl.\n- Python requests.\n\nNote: I assume this means only testing it with one of these. I could not get postman working. This could be clarified whether or not this means testing with all of them or only one.\n","metadata":{}},{"cell_type":"markdown","source":"curl\n```bash\n(LLM3) santeri@LAPTOP-67I7VNKD:~/LLM/LLM-tech3$ curl -X 'POST' 'http://127.0.0.1:8000/analyze/' -H 'Content-Type: application/json' -d '{\"text\": \"The movie had stunning visuals and a captivating soundtrack, but the plot was so convoluted and poorly paced that it left me feeling both amazed and frustrated at the same time.\", \"model\": \"llama\"}'\n[\"{\"sentiment\":\"negative\",\"confidence\":0.8214}\"]\n\n(LLM3) santeri@LAPTOP-67I7VNKD:~/LLM/LLM-tech3$ curl -X 'POST' 'http://127.0.0.1:8000/analyze/' -H 'Content-Type: application/json' -d '{\"text\": \"The movie had stunning visuals and a captivating soundtrack, but the plot was so convoluted and poorly paced that it left me feeling both amazed and frustrated at the same time.\", \"model\": \"custom\"}'\n{\"sentiment\":\"negative\",\"confidence\":0.9932}\n","metadata":{}},{"cell_type":"markdown","source":"**Step 9: Define the Llama 3 Prompt (1 point)**\n1. Write a clear and reusable prompt for the Llama 3 model in Groq Cloud.\nExample: can be improved more\n\n> \"Classify the sentiment of this text as positive or negative:'This movie was fantastic'\"\n","metadata":{}},{"cell_type":"markdown","source":">system_prompt = (\n                \"You are a highly accurate AI model specializing in binary sentiment analysis of text-based reviews. \"\n                \"You will classify the given text as either 'positive' or 'negative', with no intermediate or neutral categories. \"\n                \"Analyze the sentiment of the following text and respond strictly in the format: \"\n                \"{\\\"sentiment\\\":\\\"negative\\\",\\\"confidence\\\":0.9982}. \"\n                \"Do not include any additional explanation, comments, or formatting beyond this JSON structure. \"\n                \"The confidence score must be a float between 0 and 1, rounded to four decimal places.\"\n            )","metadata":{}},{"cell_type":"markdown","source":"**Step 10: Test with Both Models (1 point)**\n1. Verify that the API works for both the fine-tuned model and the Llama 3 model.\n2. Ensure the results return the sentiment score too.\n3. For Groq you can add into prompt,\n4. ?\n\nNote: I don't understand parts 3 and 4 of this step. 3 seems like a sentence cut short, and 4. is just empty? Only completed 1 and 2.","metadata":{}},{"cell_type":"markdown","source":"**Part 3: UI Design and Explanation (3 points)**","metadata":{}},{"cell_type":"markdown","source":"**Step 11: React UI Design (1 point)**\n- A text input field for user input.\n- A dropdown menu for model selection:\n  - Custom Model.\n  - Llama 3.\n- A button labeled \"Analyze Sentiment\" to send input and selected model to the backend API.\n- A result display section showing:\n  - Sentiment (positive or negative).\n  - Confidence score(optional)\n\n\nThe code for the react app is in github repo","metadata":{}},{"cell_type":"markdown","source":"**Step 12: Submit GitHub Repository (1 point)**\n1. Upload all code (notebook, backend, and UI explanation) to a public GitHub repository.\n2. Include a README.md file that explains how to:\n- Install dependencies.\n- Run the notebook and API locally.\n- Use the endpoints.","metadata":{}},{"cell_type":"markdown","source":"**Step 13: Record a YouTube Demo Video (1 point)**\n1. Record a demo video (2-3 minutes) showing:\n - Testing the system with both models (custom and llama).\n - One question with custom fine and one with llam3 any llama 3 will be fine.\n\n2. Upload the video to YouTube and include the link in your notebook.\n\nLink: https://www.youtube.com/shorts/x5OkZ7pg7HY\nThe video is shorter. Testing the react api does not take 2-3 minutes.","metadata":{}}]}